{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateuszmilewski/quickCsvTest001/blob/main/pyspark001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## just some pip to install the spark for the python"
      ],
      "metadata": {
        "id": "qHJsCET3qwQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orO5PUtVqCaO",
        "outputId": "6b08b923-8f01-4567-ee43-8a9ed6329888"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=193d4ada78127919758c8720144e4e530173592b6839b32417ac9c8e4e6e0e9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pyspark workspace"
      ],
      "metadata": {
        "id": "WyGdi3y2KgUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## some hello world exmaple"
      ],
      "metadata": {
        "id": "ECh6bi_Xq1rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"HelloWorld\").getOrCreate()\n",
        "\n",
        "# Create a Resilient Distributed Dataset (RDD)\n",
        "data = [\"Hello\", \"World\"]\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "\n",
        "# Perform a map operation on the RDD\n",
        "result = rdd.map(lambda x: x + \" PySpark!\").collect()\n",
        "\n",
        "# Print the result\n",
        "for item in result:\n",
        "    print(item)\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "BgEqWlil5irX",
        "outputId": "2f6463ef-8cde-4b10-d247-e33fbf662383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello PySpark!\n",
            "World PySpark!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## to generate csv file - lets check if this work!"
      ],
      "metadata": {
        "id": "qoqky1KTsDEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wow this is really good - below code just generated for me the file"
      ],
      "metadata": {
        "id": "0WbHobmasM09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Sample data\n",
        "companies = [\n",
        "    \"Acme Corporation\",\n",
        "    \"Widget Innovators\",\n",
        "    \"Global Ventures\",\n",
        "    \"Tech Solutions Ltd\",\n",
        "    \"Quantum Industries\",\n",
        "    \"NexTech Systems\",\n",
        "    \"Data Dynamics\",\n",
        "    \"Alpha Innovations\",\n",
        "    \"Infinite Insights\",\n",
        "    \"Bright Ideas Co.\"\n",
        "]\n",
        "\n",
        "# Generate random data\n",
        "rows = []\n",
        "for _ in range(10):\n",
        "    company = random.choice(companies)\n",
        "    revenue = random.randint(500000, 3000000)\n",
        "    employees = random.randint(10, 100)\n",
        "    rows.append([company, revenue, employees])\n",
        "\n",
        "# Write to CSV file\n",
        "with open(\"random_business_data.csv\", \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Company Name\", \"Revenue (in USD)\", \"Number of Employees\"])\n",
        "    writer.writerows(rows)\n",
        "\n",
        "print(\"CSV file 'random_business_data.csv' created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo8807tBsGbG",
        "outputId": "437649d2-e1b9-461f-9ab2-08d115459983"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'random_business_data.csv' created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## non becuase I have this csv file here - lets try to see it through pyspark"
      ],
      "metadata": {
        "id": "6PSnGQP2srDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sWm2LwJ8syO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"Read CSV Example\").getOrCreate()\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = spark.read.csv(\"random_business_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the DataFrame\n",
        "df.show()\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8bG2liMsym2",
        "outputId": "ee287ecd-80fb-4e2a-eeb4-4040db585cff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------------+-------------------+\n",
            "|      Company Name|Revenue (in USD)|Number of Employees|\n",
            "+------------------+----------------+-------------------+\n",
            "|Tech Solutions Ltd|         1009180|                 74|\n",
            "|  Bright Ideas Co.|         2530429|                 29|\n",
            "| Alpha Innovations|         1065817|                 85|\n",
            "| Infinite Insights|         2060767|                 67|\n",
            "|  Bright Ideas Co.|          549265|                 53|\n",
            "|  Acme Corporation|         2361316|                 20|\n",
            "| Widget Innovators|         1823113|                 70|\n",
            "| Alpha Innovations|         1116789|                 45|\n",
            "|   Global Ventures|         1964298|                 61|\n",
            "|  Acme Corporation|         1349683|                 29|\n",
            "+------------------+----------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "We use the avg and max functions from pyspark.sql.functions to compute the average revenue and maximum number of employees, respectively.\n",
        "The results are printed to the console.\n",
        "Feel free to explore more statistical analyses or customize the code further based on your requirements! üìäüöÄ‚ú®"
      ],
      "metadata": {
        "id": "I_ozXkr2tPq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, max, min\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"Business Statistics\").getOrCreate()\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = spark.read.csv(\"random_business_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the DataFrame\n",
        "df.show()\n",
        "\n",
        "# Calculate average revenue\n",
        "avg_revenue = df.select(avg(\"Revenue (in USD)\")).collect()[0][0]\n",
        "print(f\"Average Revenue: ${avg_revenue:.2f}\")\n",
        "\n",
        "# Calculate maximum number of employees\n",
        "max_employees = df.select(max(\"Number of Employees\")).collect()[0][0]\n",
        "print(f\"Maximum Employees: {max_employees}\")\n",
        "\n",
        "# Calculate avr number of employees\n",
        "min_employees = df.select(min(\"Number of Employees\")).collect()[0][0]\n",
        "print(f\"average number of Employees: {min_employees}\")\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoJDAHCutVtR",
        "outputId": "487fcc92-d59c-46a1-ce38-c4993d812623"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------------+-------------------+\n",
            "|      Company Name|Revenue (in USD)|Number of Employees|\n",
            "+------------------+----------------+-------------------+\n",
            "|Tech Solutions Ltd|         1009180|                 74|\n",
            "|  Bright Ideas Co.|         2530429|                 29|\n",
            "| Alpha Innovations|         1065817|                 85|\n",
            "| Infinite Insights|         2060767|                 67|\n",
            "|  Bright Ideas Co.|          549265|                 53|\n",
            "|  Acme Corporation|         2361316|                 20|\n",
            "| Widget Innovators|         1823113|                 70|\n",
            "| Alpha Innovations|         1116789|                 45|\n",
            "|   Global Ventures|         1964298|                 61|\n",
            "|  Acme Corporation|         1349683|                 29|\n",
            "+------------------+----------------+-------------------+\n",
            "\n",
            "Average Revenue: $1583065.70\n",
            "Maximum Employees: 85\n",
            "average number of Employees: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"Read CSV Example\").getOrCreate()\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = spark.read.csv(\"random_business_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the DataFrame\n",
        "df.show()\n",
        "\n",
        "\n",
        "header_col = 'Company Name'\n",
        "cols_minus_header = df.columns\n",
        "cols_minus_header.remove(header_col)\n",
        "\n",
        "\n",
        "# this is strange!\n",
        "##########################################\n",
        "df_transposed = (\n",
        "    df.groupBy()\n",
        "    .pivot(header_col)\n",
        "    .agg(F.first(F.array(*cols_minus_header)))\n",
        "    .withColumn(header_col, F.array(*map(F.lit, cols_minus_header)))\n",
        ")\n",
        "##########################################\n",
        "\n",
        "\n",
        "\n",
        "print('Quasi Transpose: ')\n",
        "\n",
        "# Show the transposed DataFrame\n",
        "df_transposed.show(truncate=False)\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7trUFeSRxVWQ",
        "outputId": "c1a0adb5-2c1b-4207-f79a-2c994d751dbc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------------+-------------------+\n",
            "|      Company Name|Revenue (in USD)|Number of Employees|\n",
            "+------------------+----------------+-------------------+\n",
            "|Tech Solutions Ltd|         1009180|                 74|\n",
            "|  Bright Ideas Co.|         2530429|                 29|\n",
            "| Alpha Innovations|         1065817|                 85|\n",
            "| Infinite Insights|         2060767|                 67|\n",
            "|  Bright Ideas Co.|          549265|                 53|\n",
            "|  Acme Corporation|         2361316|                 20|\n",
            "| Widget Innovators|         1823113|                 70|\n",
            "| Alpha Innovations|         1116789|                 45|\n",
            "|   Global Ventures|         1964298|                 61|\n",
            "|  Acme Corporation|         1349683|                 29|\n",
            "+------------------+----------------+-------------------+\n",
            "\n",
            "Quasi Transpose: \n",
            "+----------------+-----------------+----------------+---------------+-----------------+------------------+-----------------+---------------------------------------+\n",
            "|Acme Corporation|Alpha Innovations|Bright Ideas Co.|Global Ventures|Infinite Insights|Tech Solutions Ltd|Widget Innovators|Company Name                           |\n",
            "+----------------+-----------------+----------------+---------------+-----------------+------------------+-----------------+---------------------------------------+\n",
            "|[2361316, 20]   |[1065817, 85]    |[2530429, 29]   |[1964298, 61]  |[2060767, 67]    |[1009180, 74]     |[1823113, 70]    |[Revenue (in USD), Number of Employees]|\n",
            "+----------------+-----------------+----------------+---------------+-----------------+------------------+-----------------+---------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}